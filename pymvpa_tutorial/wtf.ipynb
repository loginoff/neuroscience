{
 "metadata": {
  "name": "",
  "signature": "sha256:8697507c8773761d50aed4d135181f88a9fbc08016068c0fc891999b405a09e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "import nibabel as nb\n",
      "from mvpa2.datasets.mri import fmri_dataset\n",
      "from mvpa2.misc.io import SampleAttributes\n",
      "from mvpa2.datasets import vstack\n",
      "from mvpa2.mappers.detrend import PolyDetrendMapper\n",
      "from mvpa2.mappers.detrend import poly_detrend\n",
      "from mvpa2.mappers.zscore import ZScoreMapper\n",
      "from mvpa2.mappers.zscore import zscore\n",
      "%pylab --no-import-all inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This block takes care of parsing the different condition onsets from the supplemental data for each run, maps these onsets (which are in seconds from the beginning of each run) onto brain volumes and stores them as sample attributes to the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "condition_key = {\n",
      "'cond001':'house',\n",
      "'cond002':'scrambledpix',\n",
      "'cond003':'cat',\n",
      "'cond004':'shoe',\n",
      "'cond005':'bottle',\n",
      "'cond006':'scissors',\n",
      "'cond007':'chair',\n",
      "'cond008':'face',\n",
      "}\n",
      "TR=2.5\n",
      "def parse_targets(onset_path, ds):\n",
      "    targets = np.chararray(ds.shape[0],itemsize=12)\n",
      "    targets[:] = 'rest'\n",
      "    condfiles=glob.glob(os.path.join(onset_path,'cond*'))\n",
      "    for cfile in condfiles:\n",
      "        condition = os.path.basename(cfile).rstrip('.txt')\n",
      "        with open(cfile,'r') as f:\n",
      "            for line in f:\n",
      "                start, duration, weight = line.split()\n",
      "                startidx = float(start) / TR\n",
      "                endidx = (float(start)+float(duration)) / TR\n",
      "                targets[int(startidx):int(endidx)+1] = condition_key[condition]\n",
      "    ds.sa['targets']=targets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the data for subject 1 for all 12 runs and concatenate into a single dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#boldpath = '../tutorial_data/data/sub001/BOLD/task001_run001/bold.nii.gz'\n",
      "boldpath = '../ds105/sub001/BOLD/task001_run0%02d/bold.nii.gz'\n",
      "#onset_path = '../tutorial_data/data/sub001/model/model001/onsets/task001_run001'\n",
      "onset_path = '../ds105/sub001/model/model001/onsets/task001_run0%02d/'\n",
      "ds = fmri_dataset(samples=boldpath % 1)\n",
      "parse_targets(onset_path % 1,ds)\n",
      "ds.sa['chunks']=np.zeros(len(ds))\n",
      "\n",
      "for i in xrange(2,13):\n",
      "    dsi = fmri_dataset(samples=boldpath % i)\n",
      "    parse_targets(onset_path % i, dsi)\n",
      "    chunks = np.empty(len(dsi))\n",
      "    chunks[:]=i-1\n",
      "    dsi.sa['chunks']=chunks\n",
      "    \n",
      "    ds = vstack((ds,dsi),0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poly_detrend(ds, polyord=1, chunks_attr='chunks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.sa.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['chunks', 'time_indices', 'targets', 'time_coords']"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}