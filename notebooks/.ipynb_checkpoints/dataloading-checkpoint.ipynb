{
 "metadata": {
  "name": "",
  "signature": "sha256:4c952789b097a8008b87e8ee28c956cff035b597dc2671c79e41549efd8f4c86"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "import nibabel as nb\n",
      "import re\n",
      "from mvpa2.datasets.mri import fmri_dataset\n",
      "from mvpa2.misc.io import SampleAttributes\n",
      "from mvpa2.datasets import vstack\n",
      "from mvpa2.mappers.detrend import PolyDetrendMapper\n",
      "from mvpa2.mappers.detrend import poly_detrend\n",
      "from mvpa2.mappers.zscore import ZScoreMapper\n",
      "from mvpa2.mappers.zscore import zscore\n",
      "from mvpa2.clfs.knn import kNN\n",
      "from mvpa2.clfs.svm import LinearCSVMC\n",
      "from mvpa2.clfs.distance import one_minus_correlation\n",
      "from mvpa2.mappers.fx import BinaryFxNode\n",
      "from mvpa2.mappers.fx import mean_group_sample\n",
      "from mvpa2.generators.partition import HalfPartitioner\n",
      "from mvpa2.generators.partition import NFoldPartitioner\n",
      "from mvpa2.measures.base import CrossValidation\n",
      "%pylab --no-import-all inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_openfmri_ds(root, subject, mask=None, filterfun=None):\n",
      "    TR=3.0\n",
      "    \n",
      "    ####Define helper functions for loading different parts of the data####\n",
      "    def read_condition_keys(DSROOT):\n",
      "        maxlength = 0\n",
      "        def pick_fields(keys, line):\n",
      "            fields = line.split()\n",
      "            try:\n",
      "                keys[fields[0]][fields[1]] = ' '.join(fields[2:])\n",
      "            except KeyError:\n",
      "                keys[fields[0]]={fields[1] : ' '.join(fields[2:])}\n",
      "            return keys\n",
      "\n",
      "        with open(os.path.join(DSROOT, \n",
      "                                    'models/model001/condition_key.txt'),'r') as keyfile:\n",
      "            return reduce(pick_fields,keyfile,{})\n",
      "        \n",
      "    def parse_condition_onsets(path):\n",
      "        condfiles=glob.glob(os.path.join(path, 'cond*'))\n",
      "        timeline = []\n",
      "        for cfile in condfiles:\n",
      "            cond_name = os.path.basename(cfile).rstrip('.txt')\n",
      "            with open(cfile,'r') as cfh:\n",
      "                for line in cfh:\n",
      "                    start, duration, weight = line.split()\n",
      "                    timeline.append((float(start), float(duration), cond_name))\n",
      "        timeline.sort()\n",
      "        return timeline\n",
      "        \n",
      "    def extract_task_and_run(string):\n",
      "        m=re.search('task([0-9]+)_run([0-9]+)', string)\n",
      "        return int(m.group(1)), int(m.group(2))\n",
      "\n",
      "    def load_run(runstring):\n",
      "        ds=fmri_dataset(samples=os.path.join(root,subject,'BOLD',runstring,'bold.nii.gz'))\n",
      "        task, run = extract_task_and_run(runstring)\n",
      "\n",
      "        ds.sa['chunks'] = np.empty(len(ds))\n",
      "        ds.sa.chunks.fill(run)\n",
      "        ds.sa['task'] = np.empty(len(ds))\n",
      "        ds.sa.task.fill(task)\n",
      "        return ds\n",
      "    \n",
      "    def merge_conditions_onto_ds(ds, onsets):\n",
      "        targets = np.chararray(ds.shape[0],itemsize=17)\n",
      "        targets.fill('rest')\n",
      "        for cond in onsets:\n",
      "            start, duration, condition = cond\n",
      "            startidx = int(start/TR)\n",
      "            endidx = int((start+duration)/TR)\n",
      "            targets[startidx:endidx+1] = condition_keys['task001'][condition]\n",
      "        ds.sa['targets']=targets\n",
      "    \n",
      "    ##Actual data loading begins here\n",
      "    condition_keys = read_condition_keys(root)\n",
      "    \n",
      "    allruns = map(lambda x: os.path.basename(x),\n",
      "                glob.glob(os.path.join(root, subject,'BOLD/task*')))\n",
      "    \n",
      "    if filterfun:\n",
      "        allruns = filter(filterfun,allruns)\n",
      "    \n",
      "    alldata=[]\n",
      "    for run in allruns:\n",
      "        ds=load_run(run)\n",
      "        onsets=parse_condition_onsets(os.path.join(root,subject,'model/model001/onsets/',run))\n",
      "        merge_conditions_onto_ds(ds,onsets)\n",
      "        alldata.append(ds)\n",
      "        \n",
      "    merged = vstack(alldata)\n",
      "    merged.a.update(alldata[0].a)\n",
      "    return merged"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds=load_openfmri_ds('../data/ds107','sub001')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.sa.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "['chunks', 'time_indices', 'task', 'targets', 'time_coords']"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "detrender = PolyDetrendMapper(polyord=1, chunks_attr='chunks')\n",
      "ds = ds.get_mapped(detrender)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zscorer = ZScoreMapper(param_est=('targets',['rest']))\n",
      "zscore(ds, param_est=('targets',['rest']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "averager=mean_group_sample(['targets'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds=ds.get_mapped(averager)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}